{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b080581-43d1-4eee-afb5-d76feeec9878",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Return of the Multi-Armed Bandit</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eb6a26-d222-4072-ae3b-1d76a63fc644",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> \n",
    "    Section Introduction: The Explore-Exploit Dilemma\n",
    "</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Em análises estatísticas, a amostra requerida para termos um grande poder estatístico pode ser alta demais. Nesse caso, os pesquisadores podem se sentir tentados a sacrificar parte desse poder com um grupo menor, a fim de colher mais rapidamente os resultados, podendo usufruir das conclusões tiradas.\n",
    "        </li>\n",
    "        <li>\n",
    "            Esse conflito de interesses é conhecido como <i> Explore-Exploit Dilemma</i>.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc5e11-8c66-4e87-a2b2-d7f35c129dc4",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Aplicações do Explore-Exploit Dilemma</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            O Explore-Exploit Dilemma pode ser bastante sentido em pesquisas de mercado. Quando uma empresa decide realizar dois tipos de comerciais, está pondo em risco a imagem de seu produto para o público exposto ao de menor popularidade. Ao mesmo tempo, a companhia deseja ter uma amostra grande o bastante para confiar nas conclusões do estudo.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b122c10-c6e1-4e12-8b13-d0f44b76a83e",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> \n",
    "    Epsilon-Greedy Theory\n",
    "</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Epsilon-Greedy é um dos métodos fundamentais de RL. Ele é baseado no algoritmo <i>Greedy</i>\n",
    "        </li>\n",
    "        <li>\n",
    "            Uma busca Greedy consistiria em apenas escolhermos a opção com maior probabilidade de sucesso.\n",
    "        </li>\n",
    "        <li>\n",
    "            Por exemplo, suponha que jogamos em dois caça-níqueis, vencendo no primeiro, e perdendo no segundo. Pela lógica Greedy, deveremos jogar apenas no primeiro caça-níquel infinitamente.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc1fcb7-c658-4c7d-bd4b-753dd3c4d73b",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Lógica do Epsilon-Greedy</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Mas é claro: o algoritmo Greedy não leva em conta o tamanho de nossa amostragem. Por isso, o Epsilon-Greedy impõe uma pequena probabilidade $\\epsilon$ de executarmos uma opção aleatória à cada iteração.\n",
    "        </li>\n",
    "        <li>\n",
    "            Dessa forma, nos permitimos explorar a rota de maior sucesso, ao mesmo tempo em que construímos uma amostragem grande o bastante para avaliarmos todas as demais. \n",
    "        </li>\n",
    "        <li>\n",
    "            Costumamos definir $\\epsilon$ como 5% ou 10%. Ainda é possível configurarmos um decaimento, no decorrer das iterações.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a83f8ad-f49b-44a5-b0ca-fcbc4b8f8a27",
   "metadata": {},
   "source": [
    "<figure>\n",
    "        <center style='margin-top:20px'>\n",
    "            <img src='img/02_epsilon_decay.png'>\n",
    "                <figcaption> Opções de Epsilon Decay.</figcaption>\n",
    "        </center>\n",
    "    </figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0703007-ff09-4882-bf16-00374297710f",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> \n",
    "     Calculating a Sample Mean\n",
    "</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Nessa aula, apenas somos aconselhados em como computar o valor médio de funções. \n",
    "        </li>\n",
    "        <li>\n",
    "            Como, em teoria, vamos acioná-las infinitamente, não seria adequado armazenarmos todos os seus outputs num vetor para computar a sua média. Isso porque o algoritmo de soma é $O(n)$.\n",
    "        </li>\n",
    "        <li>\n",
    "            AO invés disso, armazenamos a média da última iteração numa variável, e computamos uma média ponderada:\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bd3ae65-296e-4a98-b903-6e4ce5241cd0",
   "metadata": {},
   "source": [
    "<figure>\n",
    "        <center style='margin-top:20px'>\n",
    "            <img src='img/02_mean.png'>\n",
    "        </center>\n",
    "    </figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a9fd3-e81c-4e44-ac89-631973813394",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Optimistic Initial Values Theory</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            O Optimistic Initial Values consiste numa adaptação do Greedy Method. Nele, definimos as médias iniciais de todos os candidatos como um número superestimado.\n",
    "        </li>\n",
    "        <li>\n",
    "            A ideia por trás desse ajuste é forçarmos uma exploração mais ampla sobre as metodologias disponíveis. Quanto maior a média inicial, mais exploração nos permitimos fazer.\n",
    "        </li>\n",
    "        <li>\n",
    "            Porém, é um algoritmo limitado. Porque ainda assim, as alternativas de média abaixo da máxima serão sub-exploradas, ficando com uma estimativa acima de seu valor real.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9170d726-ba6a-44e0-86d7-f2a2a0421c10",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<figure>\n",
    "        <center style='margin-top:20px'>\n",
    "            <img src='img/02_optimistic_plot.png'>\n",
    "                <figcaption>  Exemplo de gráfico de um Optimistic Initial Values.</figcaption>\n",
    "        </center>\n",
    "    </figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba82c35b-13e6-4e80-9e3b-0f7df862be7f",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> UCB1 Theory</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            O UCB-1 é um algoritmo que recorre a uma <i> fronteira probabilística</i> a fim de definir a ferramenta escolhida. No caso, usamos a <strong>Hoeffding Inequality</strong>. \n",
    "        </li>\n",
    "        <li>\n",
    "            A escolha do item se dará como:\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36681efc-00bb-48d2-bdf1-b6b28a6c4fa7",
   "metadata": {},
   "source": [
    "<figure>\n",
    "        <center style='font-size:20px;margin-top:20px'>\n",
    "            $\\displaystyle \\arg\\max_{j}{\\left(\\overline{X}_{n_{j}}+\\sqrt{\\alpha\\frac{\\log{N}}{n_j}}\\right)}$\n",
    "                <figcaption style='font-size:15px'>\n",
    "                    Equação de um UCB-1\n",
    "                </figcaption>\n",
    "        </center>\n",
    "    </figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143af11e-f15f-4e5e-b71d-bd6992e54964",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            $\\overline{X}_{n_j}$ tendencia o algoritmo à <i>exploitation</i>, enquanto $\\sqrt{\\alpha\\frac{\\log{N}}{n_j}}$ à <i> exploration</i>. $\\alpha$, normalmente definido como 2, é um hiperparâmetro que controla a ênfase de exploration desejada pelo usuário.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595dde7f-f356-4a58-a226-ade2132656ae",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Método de Inicialização</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            No step 0 do UCB, nos encontramos em uma situação de indeterminação, porque $\\frac{\\log{N}}{n_j}=\\frac{-\\infty}{\\infty}$.\n",
    "        </li>\n",
    "        <li>\n",
    "            Levando isso em conta, recomenda-se executarmos cada uma das ferramentas uma vez, a fim de que $N$ e $n_j$ sejam positivos no início do UCB-1.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e02cdfe-29bc-4621-9aba-897987f78f1b",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> \n",
    "    <a href='https://www.lancaster.ac.uk/stor-i-student-sites/libby-daniells/wp-content/uploads/sites/9/2020/05/LibbyReport.pdf'>Bayesian Bandits / Thompson Sampling Theory</a>\n",
    "</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Thompson Sampling consiste em um algoritmo que se baseia na relação entre a Distribuição Binomial e Beta.\n",
    "        </li>\n",
    "        <li>\n",
    "            A probabilidade de sucesso $\\theta_{k}$ de cada alternativa $k\\in[1,K]$ é associada a uma Distribuição Beta.\n",
    "        </li>\n",
    "        <li>\n",
    "            A cada iteração, escolhemos a ação da Distribuição Beta de maior valor médio. Após a coleta de resultados, atualizamos os seus parâmetros para $\\alpha+y$ e $\\beta+n-y$.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa75d6cb-4370-43b8-85d0-b38717491b0e",
   "metadata": {},
   "source": [
    "<figure>\n",
    "        <center style='font-size:20px;margin-top:20px'>\n",
    "            $E[X]=\\frac{\\alpha}{\\alpha+\\beta}$\n",
    "            <figcaption style='font-size:15px'> Valor esperado da Distribuição Beta.</figcaption>\n",
    "        </center>\n",
    "    </figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afda09fc-6c43-49a7-a199-b7d00d32228d",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> General Thompson Sampling</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Apesar de esse algoritmo ser bastante popular em amostragens binomiais, ele pode ser aplicado em qualquer outra espécie de distribuição.\n",
    "        </li>\n",
    "        <li>\n",
    "            Apenas repare que a prior e posterior dessa distribuição podem não ser iguais, o que tornará o código do seu experimento mais complicado.\n",
    "        </li>\n",
    "        <li>\n",
    "            Para saber as respectivas priors e posteriors da sua distribuição de interesse, pesquise em textos sobre estatística.\n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce55f88-c575-4d5f-8373-5fc860960663",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> Nonstationary Bandits\n",
    "</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Dizemos que um Bandit ´é não-estacionário quando sua probabilidade de sucesso se altera com o passar do tempo.\n",
    "        </li>\n",
    "        <li>\n",
    "            Levando isso em conta, usar a média aritmética do reward pode ser prejudicial, porque as primeiras instâncias da série podem não condizer com as características atuais do Bandit.\n",
    "        </li>\n",
    "        <li>\n",
    "            Com isso, recomenda-se a utilização de médias móveis exponenciais (EWMA) para a atualização dos rewards. Elas têm a tendência de considerarem menos as primeiras instâncias, conforme a série for progredindo. \n",
    "        </li>\n",
    "    </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7dfa6d-23c3-4763-adb1-756bdf01f38f",
   "metadata": {},
   "source": [
    "<figure>\n",
    "        <center style='font-size:20px;margin-top:20px'>\n",
    "            $\\overline{X}_{t}=\\overline{X}_{t-1}+\\alpha (X_{t}-\\overline{X}_{t-1})$\n",
    "            <figcaption style='font-size:15px'> Equação da EWMA.</figcaption>\n",
    "        </center>\n",
    "    </figure>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
